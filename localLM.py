from transformers import AutoTokenizer, AutoModelForCausalLM

class LocalCoachingAdvisorLLM:
    def __init__(self, model_name: str = "distilgpt2", device: int = -1):
        """
        Initialize the local LLM using Hugging Face Transformers.

        :param model_name: Hugging Face model name (default: 'distilgpt2').
        :param device: Device to run the model on (-1 for CPU, 0 for GPU).
        """
        self.device = "cuda" if device == 0 else "cpu"
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForCausalLM.from_pretrained(model_name).to(self.device)

    def generate_advice(self, feedback: str) -> str:
        """
        Generate actionable coaching advice using the local Hugging Face model.

        :param feedback: Feedback text input by the coach.
        :return: Advice generated by the model.
        """
        # Create a context-specific prompt
        prompt = (
            "You are a professional coaching advisor. "
            "Analyze the following feedback about a boxing coach and provide actionable recommendations:\n"
            f"{feedback}"
        )

        try:
            # Tokenize and generate
            inputs = self.tokenizer.encode(prompt, return_tensors="pt").to(self.device)
            outputs = self.model.generate(inputs, max_length=300, num_beams=5, num_return_sequences=1)
            advice = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            return advice
        except Exception as e:
            return f"Error while generating advice: {str(e)}"

    def get_recommendations(self, feedback_data):
        """
        Generate recommendations from the provided feedback DataFrame.

        :param feedback_data: DataFrame containing student feedback.
        :return: AI-generated recommendations.
        """
        try:
            # Combine feedback into a structured format
            combined_feedback = "\n".join(
                f"- {row['Name']}: {row['Feedback']} (Satisfaction: {row['Satisfaction']})"
                for _, row in feedback_data.iterrows()
            )

            # If no feedback is available, return a warning
            if not combined_feedback.strip():
                return "No feedback available to generate recommendations."

            # Generate advice using combined feedback
            return self.generate_advice(combined_feedback)
        except Exception as e:
            return f"Error while generating recommendations: {str(e)}"